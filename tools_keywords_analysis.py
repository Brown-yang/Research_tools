import requests
from bs4 import BeautifulSoup
import csv
import os

url = 'https://dblp.uni-trier.de/db/journals/trob/trob39.html'
html_file = 'html/tro2023.html'


# ä¸‹è½½æˆ–è¯»å–ç¼“å­˜é¡µé¢
if not os.path.exists(html_file):
    print("Downloading webpage...")
    headers = {'User-Agent': 'Mozilla/5.0'}
    response = requests.get(url, headers=headers)
    response.raise_for_status()
    with open(html_file, 'w', encoding='utf-8') as f:
        f.write(response.text)
else:
    print("Using cached HTML file.")

# ç”¨ lxml åŠ é€Ÿè§£æ
with open(html_file, 'r', encoding='utf-8') as f:
    soup = BeautifulSoup(f, 'lxml')

# æŸ¥æ‰¾æ‰€æœ‰è®ºæ–‡å—
entries = soup.find_all('cite', class_='data')

results = []
for entry in entries:
    title_tag = entry.find('span', class_='title')
    author_tags = entry.find_all('span', itemprop='author')
    pages_tag = entry.find('span', itemprop='pagination')

    if title_tag and author_tags:
        title = title_tag.get_text(strip=True)
        if 'grasp' in title.lower():
            # æ ‡é¢˜æœ«å°¾å¦‚æœå·²æœ‰å¥å·å°±ä¸å†åŠ 
            title = title.strip()
            if title.endswith('.'):
                title_text = title
            else:
                title_text = title + '.'
            
            authors = [a.get_text(strip=True) for a in author_tags]
            authors_str = ', '.join(authors)
            pages = pages_tag.get_text(strip=True) if pages_tag else "N/A"
            
            # æ ¼å¼ï¼šä½œè€…ï¼ˆç¬¬ä¸€è¡Œï¼‰+æ¢è¡Œ+æ ‡é¢˜å’Œé¡µç ï¼ˆç¬¬äºŒè¡Œï¼‰
            formatted_text = f"{authors_str}:\n{title} {pages}"
            results.append([formatted_text])
            
            

# å†™å…¥ CSV æ–‡ä»¶ï¼ˆå¯ç”¨æ¢è¡Œï¼‰
csv_file = 'papers_csv/tro2023_grasp_papers.csv'
with open(csv_file, 'w', newline='', encoding='utf-8-sig') as f:
    writer = csv.writer(f)
    writer.writerow(['Paper'])
    writer.writerows(results)

print(f"\nâœ… å…±æ‰¾åˆ° {len(results)} ç¯‡åŒ…å« 'grasp' çš„è®ºæ–‡ã€‚")
print(f"ğŸ“„ å·²ä¿å­˜ä¸ºï¼š{csv_file}")
